{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Tracks Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "60b94c9daac04d1d9c1d90b263c45876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fade98b1d5b842d58a147f3994154363",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8e5f7235b5cd44e1b08ac9fddb585c4d",
              "IPY_MODEL_4adc814e08874ab791f7a1126649cc60"
            ]
          }
        },
        "fade98b1d5b842d58a147f3994154363": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e5f7235b5cd44e1b08ac9fddb585c4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_204b8d98529f434fb0de6df8a4240558",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8985f33c73744d46a5e46124735c6e9c"
          }
        },
        "4adc814e08874ab791f7a1126649cc60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_312c20f9e89e4092ba2a5af3958b9ddb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 376kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5340d7de53d84f16a84a5d0dc0a3129a"
          }
        },
        "204b8d98529f434fb0de6df8a4240558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8985f33c73744d46a5e46124735c6e9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "312c20f9e89e4092ba2a5af3958b9ddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5340d7de53d84f16a84a5d0dc0a3129a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e82a54364a145668fc9ead4c757436c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a655d8291abb4630bcffc40a08dcb5dd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_daf92aba5f07423799d779ae3951a622",
              "IPY_MODEL_67ac0a9dd19741b68c19979eb56f9a83"
            ]
          }
        },
        "a655d8291abb4630bcffc40a08dcb5dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "daf92aba5f07423799d779ae3951a622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f7a7d281008a45fcad5041a2c1acd274",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d7ebb5c7fc0a4c45bd21e3fc68892516"
          }
        },
        "67ac0a9dd19741b68c19979eb56f9a83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2a02fe4ac8c64505b9d570318769f226",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:01&lt;00:00, 278B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d1380f63d844720820a7390bd813fea"
          }
        },
        "f7a7d281008a45fcad5041a2c1acd274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d7ebb5c7fc0a4c45bd21e3fc68892516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a02fe4ac8c64505b9d570318769f226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d1380f63d844720820a7390bd813fea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a816a91dc81148d8bb8f59bc5535ff64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d06d7eda80ae43d79a892fc0b1805cab",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a95fdbf77478452f9745e2591fef0af7",
              "IPY_MODEL_6085c3a7f7a14ba7a9bd58389d0b2574"
            ]
          }
        },
        "d06d7eda80ae43d79a892fc0b1805cab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a95fdbf77478452f9745e2591fef0af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4ffb793152df45269e9ae3b047376827",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8af176edf574401181df9584e4bb3315"
          }
        },
        "6085c3a7f7a14ba7a9bd58389d0b2574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7947cac176c54707a75aceed31e6057e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:35&lt;00:00, 12.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d75152cee2a74145a42ba672e50d9c3a"
          }
        },
        "4ffb793152df45269e9ae3b047376827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8af176edf574401181df9584e4bb3315": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7947cac176c54707a75aceed31e6057e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d75152cee2a74145a42ba672e50d9c3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUKW0-nevafA",
        "colab_type": "text"
      },
      "source": [
        "# NLP Task: Lyrics Sentiment Analysis using Spotify & Transformers\n",
        "\n",
        "#### In this tutorial I implement a BERT transformer with a bi-directional GRU fine-tuning layer to estimate sentiment of lyrical data. The model outputs a real number estimate between 0-1 (extremely negative to positive). \n",
        "\n",
        "##### You can try its predictions on your favorite song's lyrics :D\n",
        "\n",
        "By using the pre-trained BERT transformer from [hugginface transformers library](https://github.com/huggingface/transformers) as an embedding layer, we only have to train an additional GRU layer for the sentiment analysis, regression task (outputting a point prediction instead of a class). To train the fine-tunning layer of the model, I use Spotify valence attribute on a lyrics datset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H22QsJmUMnd",
        "colab_type": "text"
      },
      "source": [
        "#### References: \n",
        "1. Pre-processing and loading a custom dataset, gaining a better understanding of hugginface: [BERT Fine-Tuning Tutorial with PyTorch By Chris McCormick and Nick Ryan](https://colab.research.google.com/drive/1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX). \n",
        "2. Training the fine-tunning layer: [PyTorch Sentiment Analysis by Ben Trevett](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/6%20-%20Transformers%20for%20Sentiment%20Analysis.ipynb).\n",
        "3. [6.864 Natural Language Processing Spring 2020](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-864-advanced-natural-language-processing-fall-2005/) material. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pK4TdeyI6YU",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Import Libraries and Define Constants\n",
        "\n",
        "I processed the dataset in [this notebook](https://colab.research.google.com/drive/17NWbYNiSXYfoCipbn9qXmkIL1SvCFOah):\n",
        "1. Got songs lyrics from a Kaggle database (with columns: Band, Lyrics, Song).\n",
        "2. Queried Spotify for each song [valence](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/) (as a measure of positiveness).\n",
        "3. Integrated to one dataframe, where each songs has a corresponding valence value, without nulls.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sObWr8bUdZ6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "# Check colab and silent output if there are no errors\n",
        "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit \n",
        "# Clone Github repository \n",
        "rm -rf lyrics-sentiment\n",
        "git clone https://github.com/EdenBD/lyrics-sentiment.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGgQZbOBYDHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To open a function from a different notebook\n",
        "!pip install ipynb\n",
        "# To use pre-trained BERT models\n",
        "!pip install transformers\n",
        "# Get needed function from GitHub repository \n",
        "%cd lyrics-sentiment\n",
        "from ipynb.fs.defs.Spotify_Dataset import get_spotify_valence\n",
        "%cd ..\n",
        "# To download my model from the drive\n",
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WccsmdMpJ7tT",
        "colab_type": "code",
        "outputId": "3615e5ac-2af0-460b-fc47-5e2bafa675b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "# For deterministic results. \n",
        "SEED = 0\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Mount google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk0bQzvlCYrQ",
        "colab_type": "text"
      },
      "source": [
        "#### Notebook Constants: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWeHFFieakTt",
        "colab_type": "text"
      },
      "source": [
        "If you would like to train and save your own model, approve mounting your drive and change `DRIVE_FOLDER` to your desired directory name.\n",
        "\n",
        "The `DATASET_SIZE` is small for a shorter training cycle (took me around 3 hours without GPU), but will have less optimal results. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTbXDWTzCVu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STR_PRINT_BOUND = 600\n",
        "\n",
        "# For supervised training of lyrics sentiments.\n",
        "# below this bound, the song is considered as negative.\n",
        "LOW_VALENCE_BOUND = 0.1\n",
        "# above this bound, the song is considered as positive.\n",
        "HIGH_VALENCE_BOUND = 0.9\n",
        "# in between these bounds, the song is considered as neutral.\n",
        "NEUTRAL_LOWER_BOUND = 0.3\n",
        "NEUTRAL_UPPER_BOUND = 0.5\n",
        "\n",
        "# Out of the big lyrics database, use only a few rows to decrease trainig & evaluation cycles.\n",
        "DATASET_SIZE = 1000\n",
        "\n",
        "# Split dataset to training, validation and test according to these values.\n",
        "TRAIN_SIZE = 0.7\n",
        "VALIDATION_SIZE = 0.15\n",
        "\n",
        "# Model hyperparameters\n",
        "\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.25\n",
        "BATCH_SIZE = 32 \n",
        "\n",
        "# Define used paths. \n",
        "\n",
        "# Update DRIVE_FOLDER to your gdrive folder.\n",
        "DRIVE_FOLDER = \"6864\"\n",
        "DRIVE_DIR = \"/content/gdrive/My Drive\"\n",
        "ROOT_DIR = os.path.join(DRIVE_DIR,DRIVE_FOLDER)\n",
        "\n",
        "# Save path for best epoch model. \n",
        "MODEL_NAME = \"songs-model-mse.pt\"\n",
        "SAVE_PATH = os.path.join(ROOT_DIR,MODEL_NAME)\n",
        "DATASET_FILENAME = \"labeled_lyrics_cleaned.csv\"\n",
        "READY_MODEL_ID= \"15iyOz7OR-0QWlCLq5PiW2agsBOgroHMU\"\n",
        "\n",
        "# How far off an absolute difference between label and predictions counts as correct.\n",
        "ACCURACY_THRESHOLD = 0.35"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e3sVHRUrDp7",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Prepare Pytorch Dataloader\n",
        "\n",
        "I processed the labeled lyrics dataset in [this notebook](https://colab.research.google.com/drive/17NWbYNiSXYfoCipbn9qXmkIL1SvCFOah):\n",
        "1. Got songs lyrics from [250K+ lyrics Kaggle database](https://www.kaggle.com/detkov/lyrics-dataset/metadata).\n",
        "2. Queried Spotify for each song [valence](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/) (as a measure of positiveness).\n",
        "3. Integrated to one dataframe, where each songs has a corresponding valence value, without nulls.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLGbeQ_EKaME",
        "colab_type": "code",
        "outputId": "5096777b-721a-45ed-8e22-976c40bc67a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "\n",
        "# Load lyrics with sentiment file.\n",
        "dataset_path = os.path.join(ROOT_DIR,DATASET_FILENAME)\n",
        "\n",
        "df = pd.read_csv(dataset_path, error_bad_lines=False)\n",
        "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
        "\n",
        "# Dataset size.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from dataset.\n",
        "df.sample(10)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 158,353\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>artist</th>\n",
              "      <th>seq</th>\n",
              "      <th>song</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>54246</th>\n",
              "      <td>Bad Religion</td>\n",
              "      <td>Three thousand miles of wilderness overcome by...</td>\n",
              "      <td>Against the Grain</td>\n",
              "      <td>0.753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57531</th>\n",
              "      <td>Anahi</td>\n",
              "      <td>El sabor del viento y tu amanecer\\r\\nRompe la ...</td>\n",
              "      <td>Arena Y Sol</td>\n",
              "      <td>0.771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65329</th>\n",
              "      <td>XTC</td>\n",
              "      <td>Do something for me, boys \\r\\nIf I should die ...</td>\n",
              "      <td>All You Pretty Girls [Home Demo]</td>\n",
              "      <td>0.961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123663</th>\n",
              "      <td>Avril Lavigne</td>\n",
              "      <td>Hey, hey,\\r\\nYou, you,\\r\\nI don't like your gi...</td>\n",
              "      <td>Girlfriend [The Submarines' Time Warp '66 Mix]</td>\n",
              "      <td>0.839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110284</th>\n",
              "      <td>Tom Waits</td>\n",
              "      <td>My time went so quickly, \\r\\nI went lickety-sp...</td>\n",
              "      <td>Ol' 55</td>\n",
              "      <td>0.336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61151</th>\n",
              "      <td>Elvis Presley</td>\n",
              "      <td>Oh yes I've got a lot o' living to do\\r\\nA who...</td>\n",
              "      <td>Got a Lot O' Livin to Do!</td>\n",
              "      <td>0.962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107220</th>\n",
              "      <td>Jethro Tull</td>\n",
              "      <td>Salamander, \\r\\nBorn in the sun-kissed flame.\\...</td>\n",
              "      <td>Salamander</td>\n",
              "      <td>0.592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8348</th>\n",
              "      <td>Brian McKnight</td>\n",
              "      <td>[Nelly] \\r\\nLook\\r\\nShit just ain't the same\\r...</td>\n",
              "      <td>All Night Long</td>\n",
              "      <td>0.750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135843</th>\n",
              "      <td>Neil Finn</td>\n",
              "      <td>Totally wired and the game is up\\r\\nI'm under ...</td>\n",
              "      <td>Rest of the Day Off</td>\n",
              "      <td>0.634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12215</th>\n",
              "      <td>Billy Stritch</td>\n",
              "      <td>It starts with one thing\\r\\nI don't know why\\r...</td>\n",
              "      <td>Breezin' Along with the Breeze/Live Alone and ...</td>\n",
              "      <td>0.475</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                artist  ...  label\n",
              "54246     Bad Religion  ...  0.753\n",
              "57531            Anahi  ...  0.771\n",
              "65329              XTC  ...  0.961\n",
              "123663   Avril Lavigne  ...  0.839\n",
              "110284       Tom Waits  ...  0.336\n",
              "61151    Elvis Presley  ...  0.962\n",
              "107220     Jethro Tull  ...  0.592\n",
              "8348    Brian McKnight  ...  0.750\n",
              "135843       Neil Finn  ...  0.634\n",
              "12215    Billy Stritch  ...  0.475\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmAm8EHAg7tY",
        "colab_type": "text"
      },
      "source": [
        "You can check Spotify sentiment on your choice of artist and song. \n",
        "The Kaggle dataset contains +2K artists, uploaded in October 2019. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xZxHyu-Cf_O",
        "colab_type": "code",
        "outputId": "edadadff-c6a4-42cf-d3e5-c1cd015425c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "artist_name = \"guetta\"\n",
        "song_title = \"sun\"\n",
        "\n",
        "df[(df.artist.str.contains(artist_name, case=False)) & (df.label > 0.5) & (df.song.str.contains(song_title, case=False))]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>artist</th>\n",
              "      <th>seq</th>\n",
              "      <th>song</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>96293</th>\n",
              "      <td>David Guetta</td>\n",
              "      <td>Oh wooh\\nOh gonna break it, break it, break it...</td>\n",
              "      <td>Sun Goes Down</td>\n",
              "      <td>0.695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96298</th>\n",
              "      <td>David Guetta</td>\n",
              "      <td>Let's light it up, let's light it up\\r\\nUntil ...</td>\n",
              "      <td>Lovers on the Sun</td>\n",
              "      <td>0.568</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             artist  ...  label\n",
              "96293  David Guetta  ...  0.695\n",
              "96298  David Guetta  ...  0.568\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w31q4iZz89ip",
        "colab_type": "text"
      },
      "source": [
        "Out of this dataset, I took a diversified sample of size `DATASET_SIZE`, to decrease the training cycle time. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6TC9ire7zbC",
        "colab_type": "code",
        "outputId": "2255bdb5-7e4d-4362-dc9b-7299ce119295",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "neutral = (df['label'] > NEUTRAL_LOWER_BOUND) & (df['label'] < NEUTRAL_UPPER_BOUND)\n",
        "positive = (df['label'] > HIGH_VALENCE_BOUND)\n",
        "negative = (df['label'] < LOW_VALENCE_BOUND)\n",
        "\n",
        "size_each_part = int(DATASET_SIZE/3)\n",
        "positive_df, negative_df, neutral_df = df[positive][:size_each_part], df[negative][:size_each_part], df[neutral][:size_each_part]\n",
        "\n",
        "diversified_df = pd.concat([positive_df, negative_df,neutral_df], axis=0)\n",
        "\n",
        "# Suffle dataframe rows and drop previous indices column\n",
        "diversified_df = diversified_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "lyrics = diversified_df.seq.values\n",
        "labels = diversified_df.label.values\n",
        "\n",
        "print(\"Diversified df example rows: \\n\")\n",
        "print(diversified_df[:10])\n",
        "print(\"Length of diversified dataset=\", len(diversified_df))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Diversified df example rows: \n",
            "\n",
            "            artist  ...   label\n",
            "0    Liza Minnelli  ...  0.0956\n",
            "1      Dean Martin  ...  0.9760\n",
            "2    Liza Minnelli  ...  0.9330\n",
            "3  Ella Fitzgerald  ...  0.3660\n",
            "4    Dead or Alive  ...  0.9650\n",
            "5        Dead Moon  ...  0.4300\n",
            "6          DJ Bobo  ...  0.9670\n",
            "7     Julee Cruise  ...  0.0343\n",
            "8             Ella  ...  0.4330\n",
            "9     Tony Bennett  ...  0.0812\n",
            "\n",
            "[10 rows x 4 columns]\n",
            "Length of diversified dataset= 999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBoIBMs5vafI",
        "colab_type": "text"
      },
      "source": [
        "We must tokenize the lyrical dataset, since this is what the BERT model expects as input. \n",
        "You can tokenize any text by loading the tokenizer of the imported bert model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR-dQOFxvafK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "60b94c9daac04d1d9c1d90b263c45876",
            "fade98b1d5b842d58a147f3994154363",
            "8e5f7235b5cd44e1b08ac9fddb585c4d",
            "4adc814e08874ab791f7a1126649cc60",
            "204b8d98529f434fb0de6df8a4240558",
            "8985f33c73744d46a5e46124735c6e9c",
            "312c20f9e89e4092ba2a5af3958b9ddb",
            "5340d7de53d84f16a84a5d0dc0a3129a"
          ]
        },
        "outputId": "5a53e966-3297-499a-b447-d288412142ef"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60b94c9daac04d1d9c1d90b263c45876",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_widâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxUlTeWaK6Kc",
        "colab_type": "text"
      },
      "source": [
        "Checking properties of Tokenizer on our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ND0VeZ8vafQ",
        "colab_type": "code",
        "outputId": "1ce356c3-d56e-4809-e583-db4af1f1964f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# Checking number of tokens in imported vocabulary. \n",
        "print(\"Voabulary size of Tokenizer: \",len(tokenizer.vocab),end='\\n\\n')\n",
        "\n",
        "# Print the original lyrics.\n",
        "print('Song lyrics: ')\n",
        "print(lyrics[0][:STR_PRINT_BOUND],end='\\n\\n')\n",
        "\n",
        "# Print the lyrics split into tokens.\n",
        "print('Tokenized lyrics: ', tokenizer.tokenize(lyrics[0]),end='\\n\\n')\n",
        "\n",
        "# Print the lyrics mapped to token ids.\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(lyrics[0]))\n",
        "print('Tokenized IDs: ', token_ids,end='\\n\\n')\n",
        "\n",
        "# Check out of vocabulary words in lyrics\n",
        "print('Precentage of Unknowns: ', token_ids.count(tokenizer.unk_token_id)/len(token_ids)*100, '%',end='\\n\\n')\n",
        "\n",
        "# Lyrics Sentiment\n",
        "print('Label: ', labels[0])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Voabulary size of Tokenizer:  30522\n",
            "\n",
            "Song lyrics: \n",
            "It had to be you, it had to be you;\r\n",
            "I wandered around, and finally found - the somebody who\r\n",
            "Could make me be true, could make me be blue;\r\n",
            "And even be glad, just to be sad, thinking of you.\r\n",
            "\r\n",
            "Some others I've seen, might never be mean;\r\n",
            "Might never be cross, or try to be boss,\r\n",
            "But they wouldn't do.\r\n",
            "For nobody else, gave me a thrill - with all your faults, I love you still.\r\n",
            "It had to be you, wonderful you;\r\n",
            "It had to be you.\n",
            "\n",
            "Tokenized lyrics:  ['it', 'had', 'to', 'be', 'you', ',', 'it', 'had', 'to', 'be', 'you', ';', 'i', 'wandered', 'around', ',', 'and', 'finally', 'found', '-', 'the', 'somebody', 'who', 'could', 'make', 'me', 'be', 'true', ',', 'could', 'make', 'me', 'be', 'blue', ';', 'and', 'even', 'be', 'glad', ',', 'just', 'to', 'be', 'sad', ',', 'thinking', 'of', 'you', '.', 'some', 'others', 'i', \"'\", 've', 'seen', ',', 'might', 'never', 'be', 'mean', ';', 'might', 'never', 'be', 'cross', ',', 'or', 'try', 'to', 'be', 'boss', ',', 'but', 'they', 'wouldn', \"'\", 't', 'do', '.', 'for', 'nobody', 'else', ',', 'gave', 'me', 'a', 'thrill', '-', 'with', 'all', 'your', 'faults', ',', 'i', 'love', 'you', 'still', '.', 'it', 'had', 'to', 'be', 'you', ',', 'wonderful', 'you', ';', 'it', 'had', 'to', 'be', 'you', '.']\n",
            "\n",
            "Tokenized IDs:  [2009, 2018, 2000, 2022, 2017, 1010, 2009, 2018, 2000, 2022, 2017, 1025, 1045, 13289, 2105, 1010, 1998, 2633, 2179, 1011, 1996, 8307, 2040, 2071, 2191, 2033, 2022, 2995, 1010, 2071, 2191, 2033, 2022, 2630, 1025, 1998, 2130, 2022, 5580, 1010, 2074, 2000, 2022, 6517, 1010, 3241, 1997, 2017, 1012, 2070, 2500, 1045, 1005, 2310, 2464, 1010, 2453, 2196, 2022, 2812, 1025, 2453, 2196, 2022, 2892, 1010, 2030, 3046, 2000, 2022, 5795, 1010, 2021, 2027, 2876, 1005, 1056, 2079, 1012, 2005, 6343, 2842, 1010, 2435, 2033, 1037, 16959, 1011, 2007, 2035, 2115, 19399, 1010, 1045, 2293, 2017, 2145, 1012, 2009, 2018, 2000, 2022, 2017, 1010, 6919, 2017, 1025, 2009, 2018, 2000, 2022, 2017, 1012]\n",
            "\n",
            "Precentage of Unknowns:  0.0 %\n",
            "\n",
            "Label:  0.0956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUd0azx_Mzw1",
        "colab_type": "text"
      },
      "source": [
        "Perform tokenization on the entire dataset:\n",
        "1. Convert words to voabulart indices.\n",
        "2. Add special tokens to the start [CLS] and end of each song lyrics [SEP].\n",
        "3. Pad & truncate all songs' lyrics to BERT max length (512 tokens).\n",
        "4. Use attention masks to differentiate real tokens from padding tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBrszKd2OTVJ",
        "colab_type": "code",
        "outputId": "93bf0447-eb01-45e1-de89-5d31275357a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every song:\n",
        "for lyric in lyrics:\n",
        "\n",
        "    #   Return a dictionary containing the encoded lyrics, after tokenization and mapping tokens to their vocabulary IDs.\n",
        "    #   Add special tokens [CLS], [SEP], [PAD].\n",
        "    #   Pad or truncate the sentence to max_length. \n",
        "    #   Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        lyric,                          # One song to encode.\n",
        "                        add_special_tokens = True,      # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = tokenizer.max_len, # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',          # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its 1, 0 attention mask (0 for padding indices).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "# Check Results\n",
        "print(\"----------------------\")\n",
        "print('Original: ', lyrics[1])\n",
        "print(\"----------------------\")\n",
        "print('Original Label: ', labels[1].item())\n",
        "print(\"----------------------\")\n",
        "print('Token IDs:', input_ids[1])\n",
        "print(\"----------------------\")\n",
        "print('Attention mask:', attention_masks[1])\n",
        "print(\"----------------------\")\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------\n",
            "Original:  I'm Alabamy bound\r\n",
            "They'll be no heebie-jeebies hanging 'round\r\n",
            "Just gave the meanest ticket man on earth\r\n",
            "All I'm worth to put my tootsies in an upper berth\r\n",
            "Just hear the choo-choo sound\r\n",
            "I know that soon we're gonna cover ground\r\n",
            "And then I'll holler so the world will know\r\n",
            "Here I go\r\n",
            "I'm Alabamy bound\r\n",
            "I'm Alabamy bound\r\n",
            "They'll be no heebie-jeebies hanging 'round\r\n",
            "Just gave the meanest ticket man on earth\r\n",
            "All I'm worth to put my tootsies in an upper berth\r\n",
            "Just hear the choo-choo sound\r\n",
            "I know that soon we're gonna cover the ground\r\n",
            "And then I'll holler so the world will know\r\n",
            "Here I go\r\n",
            "I'm Alabamy...\r\n",
            "I'm Alabamy bound\r\n",
            "I'm gone\n",
            "----------------------\n",
            "Original Label:  0.976\n",
            "----------------------\n",
            "Token IDs: tensor([  101,  1045,  1005,  1049, 21862,  3676,  8029,  5391,  2027,  1005,\n",
            "         2222,  2022,  2053, 18235, 11283,  1011, 15333, 15878,  3111,  5689,\n",
            "         1005,  2461,  2074,  2435,  1996,  2812,  4355,  7281,  2158,  2006,\n",
            "         3011,  2035,  1045,  1005,  1049,  4276,  2000,  2404,  2026,  2205,\n",
            "         3215,  3111,  1999,  2019,  3356, 17064,  2074,  2963,  1996, 16480,\n",
            "         2080,  1011, 16480,  2080,  2614,  1045,  2113,  2008,  2574,  2057,\n",
            "         1005,  2128,  6069,  3104,  2598,  1998,  2059,  1045,  1005,  2222,\n",
            "         7570, 10820,  2061,  1996,  2088,  2097,  2113,  2182,  1045,  2175,\n",
            "         1045,  1005,  1049, 21862,  3676,  8029,  5391,  1045,  1005,  1049,\n",
            "        21862,  3676,  8029,  5391,  2027,  1005,  2222,  2022,  2053, 18235,\n",
            "        11283,  1011, 15333, 15878,  3111,  5689,  1005,  2461,  2074,  2435,\n",
            "         1996,  2812,  4355,  7281,  2158,  2006,  3011,  2035,  1045,  1005,\n",
            "         1049,  4276,  2000,  2404,  2026,  2205,  3215,  3111,  1999,  2019,\n",
            "         3356, 17064,  2074,  2963,  1996, 16480,  2080,  1011, 16480,  2080,\n",
            "         2614,  1045,  2113,  2008,  2574,  2057,  1005,  2128,  6069,  3104,\n",
            "         1996,  2598,  1998,  2059,  1045,  1005,  2222,  7570, 10820,  2061,\n",
            "         1996,  2088,  2097,  2113,  2182,  1045,  2175,  1045,  1005,  1049,\n",
            "        21862,  3676,  8029,  1012,  1012,  1012,  1045,  1005,  1049, 21862,\n",
            "         3676,  8029,  5391,  1045,  1005,  1049,  2908,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n",
            "----------------------\n",
            "Attention mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "----------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mASqFP9rb2IW",
        "colab_type": "text"
      },
      "source": [
        "Split data to Train, Validation, Test and create a Pytorch Iterator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s49djdTqa1Pd",
        "colab_type": "code",
        "outputId": "93c1594d-eb40-474d-bf42-f63c5c7661df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Combine the inputs into a TensorDataset.\n",
        "\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Split train-validation-test sizes.\n",
        "train_size = int(TRAIN_SIZE * len(dataset))\n",
        "val_size = int(VALIDATION_SIZE * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "# Divide the dataset randomly.\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "batch_size = BATCH_SIZE\n",
        "\n",
        "# Create DataLoaders.\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  \n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size \n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset,\n",
        "            sampler = SequentialSampler(val_dataset), # Pull batches sequentially.\n",
        "            batch_size = batch_size \n",
        "        )\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "            test_dataset,\n",
        "            sampler = SequentialSampler(test_dataset), # Pull batches sequentially.\n",
        "            batch_size = batch_size \n",
        "        )\n",
        "\n",
        "print('{} training samples'.format(train_size))\n",
        "print('{} validation samples'.format(val_size))\n",
        "print('{} test samples'.format(test_size))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "699 training samples\n",
            "149 validation samples\n",
            "151 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urH2AcnVvagT",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Define the Model\n",
        "\n",
        "1. Load the same model as with the tokenizer. \n",
        "2. Build an extra layer for the sentiment task.  \n",
        "\n",
        "To have more control on the fine-tuning final layer, I decided to define my own class. However, there are many ready-to-use, task dependent BERT such as [BertForSequenceClassification](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification), which adds a single linear layer on top of the original [BERT model](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.Bert). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OlV0FOIvagT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "3e82a54364a145668fc9ead4c757436c",
            "a655d8291abb4630bcffc40a08dcb5dd",
            "daf92aba5f07423799d779ae3951a622",
            "67ac0a9dd19741b68c19979eb56f9a83",
            "f7a7d281008a45fcad5041a2c1acd274",
            "d7ebb5c7fc0a4c45bd21e3fc68892516",
            "2a02fe4ac8c64505b9d570318769f226",
            "8d1380f63d844720820a7390bd813fea",
            "a816a91dc81148d8bb8f59bc5535ff64",
            "d06d7eda80ae43d79a892fc0b1805cab",
            "a95fdbf77478452f9745e2591fef0af7",
            "6085c3a7f7a14ba7a9bd58389d0b2574",
            "4ffb793152df45269e9ae3b047376827",
            "8af176edf574401181df9584e4bb3315",
            "7947cac176c54707a75aceed31e6057e",
            "d75152cee2a74145a42ba672e50d9c3a"
          ]
        },
        "outputId": "abee3e89-4a6f-430f-f19d-87a07ae45ba9"
      },
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "bert = BertModel.from_pretrained('bert-base-uncased') # consists of 12 Transformer layers"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e82a54364a145668fc9ead4c757436c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=433, style=ProgressStyle(description_width=â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a816a91dc81148d8bb8f59bc5535ff64",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tYU71p9vagW",
        "colab_type": "text"
      },
      "source": [
        "Instead of training an embedding layer, I will use the pre-trained bert model weigths and freeze them during fine-tuning. \n",
        "\n",
        "The fine-tuning layers consists of a bidirectional [GRU](https://pytorch.org/docs/stable/nn.html#gru) and linear prediction layer for sentiment output. As stated in the [paper](https://arxiv.org/pdf/1810.04805.pdf) I will only feed to the fine-tuning layers the hidden state of the final time-step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdRFLTuSvagW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BERTLyricalSentimentGRU(nn.Module):\n",
        "    def __init__(self, bert, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
        "        \n",
        "      super().__init__()\n",
        "      \n",
        "      self.bert = bert\n",
        "      \n",
        "      embedding_dim = bert.config.to_dict()['hidden_size'] # The hidden embedding size that bert outputs\n",
        "      \n",
        "      self.gru = nn.GRU(embedding_dim,\n",
        "                        hidden_dim,\n",
        "                        num_layers = n_layers,\n",
        "                        bidirectional = bidirectional,\n",
        "                        batch_first = True,\n",
        "                        dropout = 0 if n_layers < 2 else dropout)\n",
        "      \n",
        "      self.linear = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "      \n",
        "      self.dropout = nn.Dropout(dropout)\n",
        "      \n",
        "    def forward(self, text, attention_masks):\n",
        "      \"\"\"\n",
        "        Args:\n",
        "          text(tensor): list of tokens idx, of shape (batch_size, max_sentence_len)\n",
        "          attention_masks(tensor): marks padding tokens.\n",
        "      \"\"\"\n",
        "\n",
        "      # print(\"text.shape=\",text.shape) # (batch_size, max_sentence_len)\n",
        "      # Freezed embedding weights        \n",
        "      with torch.no_grad():\n",
        "          embedded = self.bert(input_ids=text, attention_mask=attention_masks)[0] \n",
        "              \n",
        "      # print(\"embedded.shape=\",embedded.shape) #(batch_size, max_sentence_len, embed_dim)\n",
        "      \n",
        "      _, hidden = self.gru(embedded) # Do not need the outputs of the last (depth-wise) layer \n",
        "      # print(\"hidden.shape before GRU=\",hidden.shape) #(n_layers * n_directions, batch_size, embed_dim)\n",
        "      \n",
        "      # Use final time-step of the last GRU layer as linear layer input.\n",
        "      if self.gru.bidirectional:\n",
        "          hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)) \n",
        "      else:\n",
        "          hidden = self.dropout(hidden[-1,:,:])\n",
        "\n",
        "      # print(\"hidden.shape after GRU=\",hidden.shape) #(batch_size, hidden_dim *2 OR hidden_dim)\n",
        "      \n",
        "      output = self.linear(hidden)        \n",
        "      \n",
        "      # print(\"output.shape=\",output.shape) #(batch_size, linear_dim)     \n",
        "      \n",
        "      return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNnxeWgrvagZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BERTLyricalSentimentGRU(bert,\n",
        "                         HIDDEN_DIM,\n",
        "                         OUTPUT_DIM,\n",
        "                         N_LAYERS,\n",
        "                         BIDIRECTIONAL,\n",
        "                         DROPOUT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBqDsYUuMJoy",
        "colab_type": "text"
      },
      "source": [
        "Freeze BERT parameters and check learnable parameters that will be updated dduring training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Cyx0TwCvagl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Freeze parameters of bert model\n",
        "for name, param in model.named_parameters():                \n",
        "    if name.startswith('bert'):\n",
        "        param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4l4ECf8vags",
        "colab_type": "code",
        "outputId": "16136651-37a5-4f49-b944-89847ea0c59b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gru.weight_ih_l0\n",
            "gru.weight_hh_l0\n",
            "gru.bias_ih_l0\n",
            "gru.bias_hh_l0\n",
            "gru.weight_ih_l0_reverse\n",
            "gru.weight_hh_l0_reverse\n",
            "gru.bias_ih_l0_reverse\n",
            "gru.bias_hh_l0_reverse\n",
            "gru.weight_ih_l1\n",
            "gru.weight_hh_l1\n",
            "gru.bias_ih_l1\n",
            "gru.bias_hh_l1\n",
            "gru.weight_ih_l1_reverse\n",
            "gru.weight_hh_l1_reverse\n",
            "gru.bias_ih_l1_reverse\n",
            "gru.bias_hh_l1_reverse\n",
            "linear.weight\n",
            "linear.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPPqx5Dvvagw",
        "colab_type": "text"
      },
      "source": [
        "## Step 4: Train the Model\n",
        "\n",
        "Define an optimizer and [loss function](https://learn-pytorch.oneoffcoder.com/loss.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDwQ8FHNvagx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# The call to model.parameters() contains the learnable parameters.\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNFpdA0J4Idw",
        "colab_type": "text"
      },
      "source": [
        "I chose MSE since the model outputs a point prediction - a particular sentiment, and not a probability distribution. \n",
        "For a more numerically stable result I apply Sigmoid after the forward pass, as part of the loss computation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44UffK34vagz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# criterion = nn.BCEWithLogitsLoss() # Combines Softmax with Binary Cross Entropy (BCE) loss\n",
        "\n",
        "sigmoid = nn.Sigmoid()\n",
        "\n",
        "criterion = nn.MSELoss() # Since we output a single point prediction output and not a probability distribution over all possible classes."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RIszZDPvag2",
        "colab_type": "text"
      },
      "source": [
        "Check if any GPUs are available, and if available, put the model and criterion onto the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TuzbDSKvag2",
        "colab_type": "code",
        "outputId": "27ac27fe-462c-4c1e-c04c-d5c81f34b348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# If there's a GPU available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('There are {} GPU(s) available'.format(torch.cuda.device_count()))\n",
        "\n",
        "# Convert model parameters to double\n",
        "model.double()\n",
        "\n",
        "# Fit model and criterion to Cuda\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 0 GPU(s) available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmdgNPWTvag5",
        "colab_type": "text"
      },
      "source": [
        "Compute the accuracy of a batch to track predictions for our three different buckets: negative, neutral and positive sentiment. I use the threshold as an absolute difference that the prediciton can have from the label. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Brkl75Zvag6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_accuracy(preds, labels, threshold=ACCURACY_THRESHOLD):\n",
        "    \"\"\"\n",
        "    Args: \n",
        "      preds and labels are both (batch_size,) with values between [0-1].\n",
        "\n",
        "    Returns a float between 0-1, represents precentage of correct predictions in batch. \n",
        "    A correct a prediction for which abs(prediction-label) <=  threshold.\n",
        "    \"\"\"\n",
        "    # Move to CPU to be able to use numpy.\n",
        "    preds = preds.detach().cpu().numpy()\n",
        "    labels = labels.to('cpu').numpy()\n",
        "    # Filter all the correct predictions, corrrect are close enough to the labels.\n",
        "    correct_mask = np.isclose(preds, labels, rtol=threshold, atol=threshold)\n",
        "    # Get indices of correct predictions.\n",
        "    correct_indices = correct_mask.nonzero()\n",
        "    correct_labels = labels[correct_indices]\n",
        "    # Precentage of correct sentiment out of all the labels with this sentiment range.  \n",
        "    correct_negative = np.count_nonzero(correct_labels < threshold)/len(labels[labels < threshold])\n",
        "    correct_positive = np.count_nonzero(correct_labels > 1-threshold)/len(labels[labels > 1-threshold])\n",
        "    correct_neutral = np.count_nonzero((threshold <= correct_labels) & (correct_labels <= 1-threshold))/len(\n",
        "        labels[(threshold <= labels) & (labels <= 1-threshold)])\n",
        "\n",
        "    return np.sum(correct_mask) / len(labels), correct_negative, correct_positive, correct_neutral"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW9CftG4thvA",
        "colab_type": "text"
      },
      "source": [
        "Most of the training code is taken from the above mentioned [PyTorch Sentiment Analysis by Ben Trevett](https://github.com/bentrevett/pytorch-sentiment-analysis). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tClF98lvag8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_negative, epoch_positive, epoch_neutral = 0, 0, 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch_id, batch in enumerate(iterator):\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # batch contains three pytorch tensors:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        predictions = model(b_input_ids, attention_masks=b_input_mask).squeeze(1)\n",
        "        \n",
        "        loss = criterion(sigmoid(predictions), b_labels)\n",
        "        \n",
        "        acc, correct_negative, correct_positive,correct_neutral = batch_accuracy(predictions, b_labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "\n",
        "        print(\"Trained batch number: {}   | loss: {:.2f} | accuracy: {:.2f}\".format(batch_id, loss.item(), acc.item()))\n",
        "        print(\"Predicted correctly:    {:.2f}% negatives | {:.2f}% positives | {:.2f}% neutral\".format(\n",
        "            correct_negative*100, correct_positive*100, correct_neutral*100))\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        epoch_negative += correct_negative\n",
        "        epoch_positive += correct_positive\n",
        "        epoch_neutral += correct_neutral\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_negative/ len(iterator), epoch_positive/ len(iterator), epoch_neutral/ len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDzCG8HPvahA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_negative, epoch_positive,epoch_neutral = 0, 0, 0\n",
        "\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch_id, batch in enumerate(iterator):\n",
        "\n",
        "            # batch contains three pytorch tensors:\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "            \n",
        "            predictions = model(b_input_ids, attention_masks=b_input_mask).squeeze(1)            \n",
        "            loss = criterion(sigmoid(predictions), b_labels)\n",
        "        \n",
        "            acc, correct_negative, correct_positive,correct_neutral = batch_accuracy(predictions, b_labels)\n",
        "\n",
        "            print(\"Evaluated batch number: {}   | loss: {:.2f} | accuracy: {:.2f}\".format(batch_id, loss.item(), acc.item()))\n",
        "            print(\"Predicted correctly:    {:.2f}% negatives | {:.2f}% positives | {:.2f}% neutral\".format(\n",
        "            correct_negative*100, correct_positive*100, correct_neutral*100))\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "            epoch_negative += correct_negative\n",
        "            epoch_positive += correct_positive\n",
        "            epoch_neutral += correct_neutral\n",
        "\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_negative/ len(iterator), epoch_positive/ len(iterator), epoch_neutral/len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkrYYJWLvahF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DYaY0CqvahJ",
        "colab_type": "code",
        "outputId": "c2188271-7a52-404a-f5ae-63ebea047fe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# The BERT authors recommend between 2 to 4 epochs.\n",
        "\n",
        "N_EPOCHS = 3\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc, train_negative, train_positive, train_neutral = train(\n",
        "        model, train_dataloader, optimizer, criterion)\n",
        "    valid_loss, valid_acc, valid_negative, valid_positive, valid_neutral = evaluate(\n",
        "        model, validation_dataloader, criterion)\n",
        "        \n",
        "    end_time = time.time()\n",
        "        \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "        \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        print(\"Save Model with loss {:.2f} to {}\".format(best_valid_loss, SAVE_PATH))\n",
        "        save_output = open(SAVE_PATH, mode=\"wb\")\n",
        "        torch.save(model.state_dict(), save_output)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Correct Neg: {train_negative*100:.2f}% Pos: {train_positive*100:.2f}% | Neutral: {train_neutral*100:.2f}%')\n",
        "    print(f'\\t  Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% | Correct Neg: {valid_negative*100:.2f}% Pos: {valid_positive*100:.2f}% | Neutral: {valid_neutral*100:.2f}%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trained batch number: 0 with loss: 0.08 and accuracy: 0.31\n",
            "Predicted correctly 30.77% negatives, 37.50% positives and 31.73% neutral labels\n",
            "Trained batch number: 1 with loss: 0.06 and accuracy: 0.31\n",
            "Predicted correctly 18.18% negatives, 57.14% positives and 24.68% neutral labels\n",
            "Trained batch number: 2 with loss: 0.09 and accuracy: 0.25\n",
            "Predicted correctly 11.11% negatives, 50.00% positives and 38.89% neutral labels\n",
            "Trained batch number: 3 with loss: 0.05 and accuracy: 0.22\n",
            "Predicted correctly 0.00% negatives, 50.00% positives and 50.00% neutral labels\n",
            "Trained batch number: 4 with loss: 0.05 and accuracy: 0.25\n",
            "Predicted correctly 7.14% negatives, 50.00% positives and 42.86% neutral labels\n",
            "Trained batch number: 5 with loss: 0.09 and accuracy: 0.19\n",
            "Predicted correctly 0.00% negatives, 33.33% positives and 66.67% neutral labels\n",
            "Trained batch number: 6 with loss: 0.08 and accuracy: 0.31\n",
            "Predicted correctly 0.00% negatives, 50.00% positives and 50.00% neutral labels\n",
            "Trained batch number: 7 with loss: 0.05 and accuracy: 0.22\n",
            "Predicted correctly 0.00% negatives, 40.00% positives and 60.00% neutral labels\n",
            "Trained batch number: 8 with loss: 0.08 and accuracy: 0.12\n",
            "Predicted correctly 14.29% negatives, 16.67% positives and 69.05% neutral labels\n",
            "Trained batch number: 9 with loss: 0.09 and accuracy: 0.12\n",
            "Predicted correctly 14.29% negatives, 6.67% positives and 79.05% neutral labels\n",
            "Trained batch number: 10 with loss: 0.10 and accuracy: 0.28\n",
            "Predicted correctly 40.00% negatives, 28.57% positives and 31.43% neutral labels\n",
            "Trained batch number: 11 with loss: 0.13 and accuracy: 0.16\n",
            "Predicted correctly 23.08% negatives, 11.11% positives and 65.81% neutral labels\n",
            "Trained batch number: 12 with loss: 0.08 and accuracy: 0.31\n",
            "Predicted correctly 50.00% negatives, 30.77% positives and 19.23% neutral labels\n",
            "Trained batch number: 13 with loss: 0.07 and accuracy: 0.22\n",
            "Predicted correctly 25.00% negatives, 30.00% positives and 45.00% neutral labels\n",
            "Trained batch number: 14 with loss: 0.10 and accuracy: 0.09\n",
            "Predicted correctly 0.00% negatives, 25.00% positives and 75.00% neutral labels\n",
            "Trained batch number: 15 with loss: 0.10 and accuracy: 0.06\n",
            "Predicted correctly 0.00% negatives, 10.00% positives and 90.00% neutral labels\n",
            "Trained batch number: 16 with loss: 0.17 and accuracy: 0.03\n",
            "Predicted correctly 0.00% negatives, 0.00% positives and 100.00% neutral labels\n",
            "Trained batch number: 17 with loss: 0.10 and accuracy: 0.19\n",
            "Predicted correctly 7.69% negatives, 30.00% positives and 62.31% neutral labels\n",
            "Trained batch number: 18 with loss: 0.08 and accuracy: 0.22\n",
            "Predicted correctly 13.33% negatives, 33.33% positives and 53.33% neutral labels\n",
            "Trained batch number: 19 with loss: 0.05 and accuracy: 0.38\n",
            "Predicted correctly 14.29% negatives, 57.14% positives and 28.57% neutral labels\n",
            "Trained batch number: 20 with loss: 0.09 and accuracy: 0.41\n",
            "Predicted correctly 28.57% negatives, 53.85% positives and 17.58% neutral labels\n",
            "Trained batch number: 21 with loss: 0.15 and accuracy: 0.30\n",
            "Predicted correctly 7.69% negatives, 57.14% positives and 35.16% neutral labels\n",
            "Evaluated batch number: 0 with loss: 0.08 and accuracy: 0.28\n",
            "Predicted correctly 0.00% negatives, 46.15% positives and 53.85% neutral labels\n",
            "Evaluated batch number: 1 with loss: 0.12 and accuracy: 0.25\n",
            "Predicted correctly 36.36% negatives, 30.00% positives and 33.64% neutral labels\n",
            "Evaluated batch number: 2 with loss: 0.08 and accuracy: 0.28\n",
            "Predicted correctly 22.22% negatives, 44.44% positives and 33.33% neutral labels\n",
            "Evaluated batch number: 3 with loss: 0.09 and accuracy: 0.25\n",
            "Predicted correctly 14.29% negatives, 35.71% positives and 50.00% neutral labels\n",
            "Evaluated batch number: 4 with loss: 0.09 and accuracy: 0.43\n",
            "Predicted correctly 25.00% negatives, 100.00% positives and -25.00% neutral labels\n",
            "Save Model with loss 0.09 to /content/gdrive/My Drive/6864/songs-model-mse.pt\n",
            "Epoch: 01 | Epoch Time: 59m 10s\n",
            "\t Train Loss: 0.088 | Train Acc: 22.51% | Correct Neg: 13.88% Pos: 34.46% Neutral: 51.65% \n",
            "\t  Val. Loss: 0.093 |  Val. Acc: 29.82% | Correct Neg: 19.57% Pos: 51.26% Neutral: 29.16%\n",
            "Trained batch number: 0 with loss: 0.05 and accuracy: 0.44\n",
            "Predicted correctly 18.18% negatives, 46.15% positives and 35.66% neutral labels\n",
            "Trained batch number: 1 with loss: 0.06 and accuracy: 0.38\n",
            "Predicted correctly 30.00% negatives, 50.00% positives and 20.00% neutral labels\n",
            "Trained batch number: 2 with loss: 0.06 and accuracy: 0.22\n",
            "Predicted correctly 16.67% negatives, 50.00% positives and 33.33% neutral labels\n",
            "Trained batch number: 3 with loss: 0.07 and accuracy: 0.44\n",
            "Predicted correctly 33.33% negatives, 50.00% positives and 16.67% neutral labels\n",
            "Trained batch number: 4 with loss: 0.06 and accuracy: 0.50\n",
            "Predicted correctly 20.00% negatives, 77.78% positives and 2.22% neutral labels\n",
            "Trained batch number: 5 with loss: 0.06 and accuracy: 0.41\n",
            "Predicted correctly 12.50% negatives, 72.73% positives and 14.77% neutral labels\n",
            "Trained batch number: 6 with loss: 0.05 and accuracy: 0.56\n",
            "Predicted correctly 18.18% negatives, 83.33% positives and -1.52% neutral labels\n",
            "Trained batch number: 7 with loss: 0.08 and accuracy: 0.34\n",
            "Predicted correctly 0.00% negatives, 81.82% positives and 18.18% neutral labels\n",
            "Trained batch number: 8 with loss: 0.08 and accuracy: 0.28\n",
            "Predicted correctly 7.69% negatives, 75.00% positives and 17.31% neutral labels\n",
            "Trained batch number: 9 with loss: 0.05 and accuracy: 0.25\n",
            "Predicted correctly 0.00% negatives, 80.00% positives and 20.00% neutral labels\n",
            "Trained batch number: 10 with loss: 0.06 and accuracy: 0.38\n",
            "Predicted correctly 15.38% negatives, 75.00% positives and 9.62% neutral labels\n",
            "Trained batch number: 11 with loss: 0.07 and accuracy: 0.28\n",
            "Predicted correctly 0.00% negatives, 54.55% positives and 45.45% neutral labels\n",
            "Trained batch number: 12 with loss: 0.09 and accuracy: 0.25\n",
            "Predicted correctly 0.00% negatives, 46.15% positives and 53.85% neutral labels\n",
            "Trained batch number: 13 with loss: 0.06 and accuracy: 0.22\n",
            "Predicted correctly 12.50% negatives, 42.86% positives and 44.64% neutral labels\n",
            "Trained batch number: 14 with loss: 0.11 and accuracy: 0.28\n",
            "Predicted correctly 0.00% negatives, 30.77% positives and 69.23% neutral labels\n",
            "Trained batch number: 15 with loss: 0.05 and accuracy: 0.34\n",
            "Predicted correctly 15.38% negatives, 54.55% positives and 30.07% neutral labels\n",
            "Trained batch number: 16 with loss: 0.06 and accuracy: 0.34\n",
            "Predicted correctly 21.43% negatives, 50.00% positives and 28.57% neutral labels\n",
            "Trained batch number: 17 with loss: 0.11 and accuracy: 0.25\n",
            "Predicted correctly 27.27% negatives, 40.00% positives and 32.73% neutral labels\n",
            "Trained batch number: 18 with loss: 0.04 and accuracy: 0.41\n",
            "Predicted correctly 0.00% negatives, 66.67% positives and 33.33% neutral labels\n",
            "Trained batch number: 19 with loss: 0.05 and accuracy: 0.19\n",
            "Predicted correctly 7.69% negatives, 23.08% positives and 69.23% neutral labels\n",
            "Trained batch number: 20 with loss: 0.06 and accuracy: 0.31\n",
            "Predicted correctly 0.00% negatives, 50.00% positives and 50.00% neutral labels\n",
            "Trained batch number: 21 with loss: 0.08 and accuracy: 0.37\n",
            "Predicted correctly 20.00% negatives, 50.00% positives and 30.00% neutral labels\n",
            "Evaluated batch number: 0 with loss: 0.08 and accuracy: 0.38\n",
            "Predicted correctly 11.11% negatives, 46.15% positives and 42.74% neutral labels\n",
            "Evaluated batch number: 1 with loss: 0.13 and accuracy: 0.16\n",
            "Predicted correctly 27.27% negatives, 10.00% positives and 62.73% neutral labels\n",
            "Evaluated batch number: 2 with loss: 0.09 and accuracy: 0.16\n",
            "Predicted correctly 0.00% negatives, 22.22% positives and 77.78% neutral labels\n",
            "Evaluated batch number: 3 with loss: 0.11 and accuracy: 0.19\n",
            "Predicted correctly 14.29% negatives, 14.29% positives and 71.43% neutral labels\n",
            "Evaluated batch number: 4 with loss: 0.09 and accuracy: 0.24\n",
            "Predicted correctly 0.00% negatives, 66.67% positives and 33.33% neutral labels\n",
            "Epoch: 02 | Epoch Time: 59m 30s\n",
            "\t Train Loss: 0.067 | Train Acc: 33.79% | Correct Neg: 12.56% Pos: 56.84% Neutral: 30.61% \n",
            "\t  Val. Loss: 0.099 |  Val. Acc: 22.26% | Correct Neg: 10.53% Pos: 31.87% Neutral: 57.60%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHw5zD_3vahL",
        "colab_type": "text"
      },
      "source": [
        "Load the best model across epochs, the one that has the lowest validation loss. \n",
        "\n",
        "The preset is to load a previously trained model. \n",
        "If you would like to use yours, please change `use_trained_model` to True.\n",
        "\n",
        "Downloading the ready model will take a few minutes and will require your authentication when propmpted. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV4mUrqx0cuP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To authenticate to Google Cloud and download a ready to use model\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "def load_model(use_trained_model=False,shared_file_id=READY_MODEL_ID, output_name=MODEL_NAME, colab=True):\n",
        "  # Use your trained model\n",
        "  if use_trained_model:\n",
        "    model.load_state_dict(torch.load(SAVE_PATH))\n",
        "    print('Loaded the trained model Successfully')  \n",
        "\n",
        "  # Use existing model\n",
        "  else:\n",
        "    # When run in colab need a small modification to connect to Drive.\n",
        "    if colab:\n",
        "      auth.authenticate_user()\n",
        "      gauth = GoogleAuth()\n",
        "      # Download json metadata\n",
        "      gauth.credentials = GoogleCredentials.get_application_default() \n",
        "    # When run in console\n",
        "    else:\n",
        "      gauth = GoogleAuth()\n",
        "      # Create local webserver which automatically handles authentication.\n",
        "      gauth.LocalWebserverAuth() \n",
        "    # Create GoogleDrive instance with authenticated GoogleAuth instance.\n",
        "    drive = GoogleDrive(gauth)\n",
        "    # Initialize GoogleDriveFile instance with file id.\n",
        "    file_object = drive.CreateFile({'id':shared_file_id}) \n",
        "    # Download file with name MODEL_NAME\n",
        "    file_object.GetContentFile(output_name)\n",
        "    print('Downloaded model Successfully')  \n",
        "    model.load_state_dict(torch.load(output_name))\n",
        "    print('Loaded the ready-to-use model Successfully')  \n",
        "\n",
        "# Change here to use your model instead\n",
        "load_model(use_trained_model=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLPp9hYL0l1W",
        "colab_type": "text"
      },
      "source": [
        "Check model performance on test set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e482Hx-gvahM",
        "colab_type": "code",
        "outputId": "0f883155-2e0a-4eef-909c-375b95789402",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "\n",
        "test_loss, test_acc, correct_negative, correct_positive, correct_neutral = evaluate(model, test_dataloader, criterion)\n",
        "print(\"Test Loss: {:.2f} | Test Accuracy: {:.2f}%\".format(test_loss, 100*test_acc))\n",
        "print(\"--------------------------------------------------------\")\n",
        "print(\"Predicted correctly: {:.2f}% negatives | {:.2f}% positives | {:.2f}% neutral\".format(correct_negative*100, correct_positive*100, correct_neutral*100))\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluated batch number: 0   | loss: 0.10 | accuracy: 0.53\n",
            "Predicted correctly:    42.11% negatives | 87.50% positives | 40.00% neutral\n",
            "Evaluated batch number: 1   | loss: 0.10 | accuracy: 0.44\n",
            "Predicted correctly:    29.41% negatives | 60.00% positives | 60.00% neutral\n",
            "Evaluated batch number: 2   | loss: 0.08 | accuracy: 0.59\n",
            "Predicted correctly:    20.00% negatives | 90.91% positives | 63.64% neutral\n",
            "Evaluated batch number: 3   | loss: 0.09 | accuracy: 0.50\n",
            "Predicted correctly:    22.22% negatives | 76.92% positives | 40.00% neutral\n",
            "Evaluated batch number: 4   | loss: 0.13 | accuracy: 0.39\n",
            "Predicted correctly:    40.00% negatives | 44.44% positives | 25.00% neutral\n",
            "Test Loss: 0.10 | Test Accuracy: 49.08%\n",
            "--------------------------------------------------------\n",
            "Predicted correctly: 30.75% negatives | 71.96% positives | 45.73% neutral\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQphm-3fvahO",
        "colab_type": "text"
      },
      "source": [
        "## Step 5: Predict unseen samples\n",
        "\n",
        "Time to try out the model ! Test the sentiment of lyrics from the given dataset or your own. \n",
        "\n",
        "Before passing lyrical text through the model, we will convert the input text to vocabulary indices, add special tokens and convert it to a reshaped tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ8fP_KpvahP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_lyrics_sentiment(model, tokenizer, lyrics):\n",
        "    model.eval()\n",
        "    # Turn lyrics to voacbulary indices.\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(lyrics))\n",
        "    text = torch.LongTensor(input_ids).reshape(1,-1)\n",
        "\n",
        "    # Create a mask for input's padding.\n",
        "    mask = torch.LongTensor(np.where(input_ids == 0, 0, 1)).reshape(1,-1)\n",
        "\n",
        "    prediction = model(text, attention_masks=mask).squeeze(1) # in place remove all size 1 in the given dimension (here 1).\n",
        "    prediction = torch.sigmoid(prediction)\n",
        "    return prediction.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPCsZHIJBKzI",
        "colab_type": "text"
      },
      "source": [
        "#### Low valence Sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8WRMwupvahT",
        "colab_type": "code",
        "outputId": "82ce643c-35c2-40cb-82b7-1183773b5301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        }
      },
      "source": [
        "negative_sample_row = diversified_df[diversified_df.label<LOW_VALENCE_BOUND].sample()\n",
        "negative_sample_row_lyrics = negative_sample_row['seq'].item()\n",
        "print(\"Low valence lyrical sentiment analysis:\")\n",
        "print(\"-----------------\")\n",
        "print(\"Name:\", negative_sample_row.song.item())\n",
        "print(\"Artist:\", negative_sample_row.artist.item())\n",
        "print(\"-----------------\")\n",
        "print(\"Lyrics extract:\")\n",
        "print(negative_sample_row_lyrics[:STR_PRINT_BOUND])\n",
        "\n",
        "prediction = predict_lyrics_sentiment(model, tokenizer, negative_sample_row_lyrics)\n",
        "print(\"-----------------\")\n",
        "print(\"Model Prediction: {:.2f}\".format(prediction))\n",
        "print(\"Spotify Label: {:.2f}\".format(negative_sample_row.label.item()))\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Low valence lyrical sentiment analysis:\n",
            "-----------------\n",
            "Name: The End of Words\n",
            "Artist: Dead Can Dance\n",
            "-----------------\n",
            "Lyrics extract:\n",
            "Murderer!\r\n",
            "Man of fire.\r\n",
            "\r\n",
            "Murderer!\r\n",
            "I've seen the eyes of living dead.\r\n",
            "It's the same game - survival.\r\n",
            "The great mass play a waiting game.\r\n",
            "Embalmed, crippled, dying in fear of pain.\r\n",
            "All sense of freedom gone.\r\n",
            "\r\n",
            "Black sun in a white world.\r\n",
            "Like having a black sun in a white world.\r\n",
            "\r\n",
            "I have a son,\r\n",
            "His name is Eden.\r\n",
            "It's his birthright,\r\n",
            "Beyond estranged time.\r\n",
            "\r\n",
            "Give me 69 years,\r\n",
            "Another season in this hell.\r\n",
            "It's all sex and death as far as I can tell.\r\n",
            "\r\n",
            "Like Prometheus we are bound,\r\n",
            "Chained to this rock of a brave new world,\r\n",
            "Our godforsaken lot.\r\n",
            "And I feel that's all we've ever \n",
            "-----------------\n",
            "Model Prediction: 0.48\n",
            "Spotify Label: 0.07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O111uq5RBhFH",
        "colab_type": "text"
      },
      "source": [
        "#### High valence Sample "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WsfshUjvahV",
        "colab_type": "code",
        "outputId": "9db1ca1c-3c54-4fd2-f6d4-ebf5bef7d913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "source": [
        "pos_sample_row = diversified_df[diversified_df.label>HIGH_VALENCE_BOUND].sample()\n",
        "pos_sample_row_lyrics = pos_sample_row['seq'].item()\n",
        "\n",
        "print(\"High valence lyrical sentiment analysis:\")\n",
        "print(\"-----------------\")\n",
        "print(\"Name:\", pos_sample_row.song.item())\n",
        "print(\"Artist:\", pos_sample_row.artist.item())\n",
        "print(\"-----------------\")\n",
        "print(\"Lyrics extract:\")\n",
        "print(pos_sample_row_lyrics[:STR_PRINT_BOUND])\n",
        "\n",
        "prediction = predict_lyrics_sentiment(model, tokenizer, pos_sample_row_lyrics)\n",
        "print(\"-----------------\")\n",
        "print(\"Model Prediction: {:.2f}\".format(prediction))\n",
        "print(\"Spotify Label: {:.2f}\".format(pos_sample_row.label.item()))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "High valence lyrical sentiment analysis:\n",
            "-----------------\n",
            "Name: Lay Back in the Arms of Someone\n",
            "Artist: Juice Newton\n",
            "-----------------\n",
            "Lyrics extract:\n",
            "If you want my sympathy,\r\n",
            "Just open your heart to me,\r\n",
            "And you'll get whatever you'll ever need.\r\n",
            "You think that's too high for you,\r\n",
            "Oh baby, I would die for you,\r\n",
            "When there's nothin' left,\r\n",
            "You know where I'll be.\r\n",
            "\r\n",
            "Lay back in the arms of someone,\r\n",
            "You give in to the charms of someone,\r\n",
            "Lay back in the arms of someone you love.\r\n",
            "Lay back in the arms of someone,\r\n",
            "When you feel you're a part of someone,\r\n",
            "Lay back in the arms of someone you love.\r\n",
            "\r\n",
            "So baby just call on me,\r\n",
            "When you want all of me,\r\n",
            "And I'll be your lover I'll be your friend.\r\n",
            "And there's nothing I won't do,\r\n",
            "Cause baby I j\n",
            "-----------------\n",
            "Model Prediction: 0.77\n",
            "Spotify Label: 0.91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dzhJc-SOTsf",
        "colab_type": "text"
      },
      "source": [
        "#### Your own example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDoUmV294aWI",
        "colab_type": "code",
        "outputId": "75c2b891-1f3f-48a7-ad2d-ab5bcb36430a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        " \n",
        "# Your favorite lyrics!\n",
        "my_lyrics = \"\"\"\n",
        "If love is a lie, then why do we need it?\n",
        "We swear we're alive, but we're falling to pieces\n",
        "We fight like lions\n",
        "We howl at the moon\n",
        "We should be flying\n",
        "Instead we bury the truth\n",
        "But I know inside we're beautiful creatures (beautiful)\n",
        "We're beautiful creatures\n",
        "When your highs are low, keep the faith yeah\n",
        "'Cause you know that a life's never wasted\n",
        "Standing tall, shaking off the dust\n",
        "Now we know, now we know what we're made of\n",
        "We got monsters in our closets\n",
        "Had a reason but we lost it\n",
        "No direction, we've been calling through the night\n",
        "Through the night\n",
        "If love is a lie, then why do we need it?\n",
        "We swear we're alive, but we're falling to pieces\n",
        "We fight like lions\n",
        "We howl at the moon\n",
        "We should be flying\n",
        "Instead we bury the truth\n",
        "But I know inside we're beautiful creatures (beautiful)\n",
        "\"\"\"\n",
        "\n",
        "prediction = predict_lyrics_sentiment(model, tokenizer, my_lyrics)\n",
        "print(\"-----------------------\")\n",
        "print(\"Model Prediction: {:.2f}\".format(prediction))\n",
        "print(\"-----------------------\")\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------\n",
            "Model Prediction: 0.52\n",
            "-----------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpVOcV_nDgc1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d7bf3ea6-0b15-4dd3-f0a3-b1448a87ea5a"
      },
      "source": [
        "song_title = \"beautiful creatures\"\n",
        "artist = \"illenium\"\n",
        "\n",
        "# Get a token by pressing \"Get token\" here https://developer.spotify.com/console/get-audio-features-track\n",
        "# Spotify_token = \"YOUR_TOKEN\"\n",
        "Spotify_token = \"BQDlH3pC0hjMnAaoO-9JfvIyHR9U67ayouKGoeJVc4difxjy4rLAzGbbduPrZFdcmXwQpniQo5d59r9l2SEjB-A1VvsBgQAL5vhi8TTw8VgMLf60LwTf-O4eCIyqvX723vEiAU9DfKgM5IlgzpT9l2IuiqUHGALKiSuG5Mk-429Q2HO4d1VFGN0itEBtPdUKIw\"\n",
        "print(\"---------------------------------------------------------------------\")\n",
        "spotify_label = get_spotify_valence(song_title,artist,Spotify_token)\n",
        "print(\"---------------------------------------------------------------------\")\n"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------------------\n",
            "Found valence: 0.21 of the song: beautiful creatures - illenium\n",
            "---------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}